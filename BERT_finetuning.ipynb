{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19952655-e1e6-4839-a5b3-4374c669fbc2",
   "metadata": {
    "id": "19952655-e1e6-4839-a5b3-4374c669fbc2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f691afcf-2e2b-4580-8014-e91b8e2e2ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: requests in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wojtek\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.5.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wojtek\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wojtek\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (22.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (1.5.2)\n",
      "Requirement already satisfied: dill in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2022.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (1.21.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.11.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wojtek\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wojtek\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wojtek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import file_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'./csv_data/train.csv'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_settings = file_manager.get_config(section=\"bert\")\n",
    "classifier_settings[\"train_dataset\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(classifier_settings[\"train_dataset\"])\n",
    "df_test = pd.read_csv(classifier_settings[\"test_dataset\"])\n",
    "\n",
    "X = list(df_train[\"text\"])\n",
    "X_test = list(df_test[\"text\"])\n",
    "Y = list(df_train[\"label\"])\n",
    "Y_test = list(df_test[\"label\"])"
   ],
   "metadata": {
    "id": "ar6XB3lrDL0T"
   },
   "id": "ar6XB3lrDL0T"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tokenizer: transformers.models.bert.tokenization_bert_fast.BertTokenizerFast = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "\n",
    "X_train_tokenized = tokenizer(X, padding=True, truncation=True)\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True)"
   ],
   "metadata": {
    "id": "8BG-3iJCDL0U"
   },
   "id": "8BG-3iJCDL0U"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, Y)\n",
    "val_dataset = Dataset(X_test_tokenized, Y_test)"
   ],
   "metadata": {
    "id": "LPbXOc-W9E7V"
   },
   "id": "LPbXOc-W9E7V",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-german-cased\", num_labels=classifier_settings[\"num_labels\"])\n",
    "model = model.to('cuda')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzi0SCTIDL0U",
    "outputId": "b1ed92ca-03bb-4928-b46c-1cc104b9f537"
   },
   "id": "fzi0SCTIDL0U"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def compute_metrics(p):\n",
    "    print(type(p))\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='macro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ],
   "metadata": {
    "id": "Frz3TQ4BDL0V"
   },
   "id": "Frz3TQ4BDL0V"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wojtek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 17440\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1090\n",
      "  Number of trainable parameters = 109083651\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.7"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 6.00 GiB total capacity; 5.25 GiB already allocated; 0 bytes free; 5.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 30\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (loss, outputs) \u001B[38;5;28;01mif\u001B[39;00m return_outputs \u001B[38;5;28;01melse\u001B[39;00m loss\n\u001B[0;32m     23\u001B[0m trainer \u001B[38;5;241m=\u001B[39m CustomTrainer(\n\u001B[0;32m     24\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     25\u001B[0m     args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     28\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics\n\u001B[0;32m     29\u001B[0m )\n\u001B[1;32m---> 30\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:1527\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m   1524\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[0;32m   1525\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[0;32m   1526\u001B[0m )\n\u001B[1;32m-> 1527\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1528\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1531\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1532\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:1775\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   1773\u001B[0m         tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[0;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1775\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1778\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   1779\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[0;32m   1780\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   1781\u001B[0m ):\n\u001B[0;32m   1782\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   1783\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2523\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   2520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   2522\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[1;32m-> 2523\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2525\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   2526\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[16], line 16\u001B[0m, in \u001B[0;36mCustomTrainer.compute_loss\u001B[1;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_loss\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, inputs, return_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m     15\u001B[0m     labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 16\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[0;32m     17\u001B[0m     logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;66;03m# compute custom loss (suppose 3 labels with different weights)\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1566\u001B[0m, in \u001B[0;36mBertForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1560\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1561\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1562\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1563\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1564\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1566\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1567\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1568\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1569\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1571\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1572\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1573\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1574\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1575\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1576\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1578\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1580\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(pooled_output)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1021\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1012\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m   1014\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m   1015\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1016\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1019\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m   1020\u001B[0m )\n\u001B[1;32m-> 1021\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1022\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1023\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1024\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1025\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1026\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1027\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1028\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1029\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1030\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1031\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1032\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1034\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    601\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    602\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    603\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    607\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    608\u001B[0m     )\n\u001B[0;32m    609\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 610\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    611\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    612\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    613\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    614\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    615\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    616\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    617\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    620\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    621\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:496\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    485\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    486\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    493\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    494\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    495\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 496\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    503\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    505\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:426\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    418\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    424\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    425\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m--> 426\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    435\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    436\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:364\u001B[0m, in \u001B[0;36mBertSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    362\u001B[0m     attention_probs \u001B[38;5;241m=\u001B[39m attention_probs \u001B[38;5;241m*\u001B[39m head_mask\n\u001B[1;32m--> 364\u001B[0m context_layer \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_probs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue_layer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    366\u001B[0m context_layer \u001B[38;5;241m=\u001B[39m context_layer\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m    367\u001B[0m new_context_layer_shape \u001B[38;5;241m=\u001B[39m context_layer\u001B[38;5;241m.\u001B[39msize()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_head_size,)\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 6.00 GiB total capacity; 5.25 GiB already allocated; 0 bytes free; 5.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=classifier_settings[\"epochs\"],\n",
    "    per_device_train_batch_size=classifier_settings[\"batch_size\"],\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=classifier_settings[\"learning_rate\"]\n",
    ")\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose 3 labels with different weights)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, 1.0, 1.0]).to('cuda'))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "tnq0e80pDL0V",
    "outputId": "4645a6a3-5e5d-4d63-a10e-12e4a99acc43"
   },
   "id": "tnq0e80pDL0V"
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.save_model(classifier_settings[\"model_name\"])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpOyXG9oFVMY",
    "outputId": "87d28cb8-b7a7-402d-ade7-1214e3600f24"
   },
   "id": "IpOyXG9oFVMY",
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving model checkpoint to balanced-1epochs\n",
      "Configuration saved in balanced-1epochs/config.json\n",
      "Model weights saved in balanced-1epochs/pytorch_model.bin\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "### Testing model ###\n",
    "model_2 = AutoModelForSequenceClassification.from_pretrained(classifier_settings[\"model_name\"])\n",
    "model_2.to('cuda')"
   ],
   "metadata": {
    "id": "T4z8Eky0FXZu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d31a492b-9c3d-4e56-f948-05bf4439ffbf"
   },
   "id": "T4z8Eky0FXZu",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "loading configuration file balanced-1epochs/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"balanced-1epochs\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file balanced-1epochs/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at balanced-1epochs.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 5726\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'transformers.trainer_utils.EvalPrediction'>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4343\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'transformers.trainer_utils.EvalPrediction'>\n"
     ]
    }
   ],
   "source": [
    "predictions_train = trainer.predict(train_dataset)\n",
    "predictions_test = trainer.predict(val_dataset)\n",
    "predictions_train = predictions_train[0].argmax(axis=1)\n",
    "predictions_test = predictions_test[0].argmax(axis=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "m8PuHQJEDL0W",
    "outputId": "8697fbb8-18eb-4979-b0b4-21a7dff3383d"
   },
   "id": "m8PuHQJEDL0W"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "x0qZ4-SxRjd2"
   },
   "id": "x0qZ4-SxRjd2",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "names = [\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "print(\"REPORT TRAIN\")\n",
    "print(classification_report(Y, predictions_train, target_names=names, digits=4))\n",
    "matrix = confusion_matrix(Y, predictions_train)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=names)\n",
    "disp.plot()\n",
    "plt.plot()"
   ],
   "metadata": {
    "id": "wYXeaCzRGrZO",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "outputId": "81948821-05ff-40ca-dcf3-f77476ef44e5"
   },
   "id": "wYXeaCzRGrZO",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "REPORT TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive     0.6401    0.8418    0.7272      2054\n",
      "     neutral     0.7066    0.5261    0.6031      1895\n",
      "    negative     0.8166    0.7417    0.7774      1777\n",
      "\n",
      "    accuracy                         0.7063      5726\n",
      "   macro avg     0.7211    0.7032    0.7026      5726\n",
      "weighted avg     0.7169    0.7063    0.7017      5726\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"REPORT TEST\")\n",
    "print(classification_report(Y_test, predictions_test, target_names=names, digits=4))\n",
    "matrix = confusion_matrix(Y_test, predictions_test)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=names)\n",
    "disp.plot()\n",
    "plt.plot()"
   ],
   "metadata": {
    "id": "F9XbKo9ENsGN",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "outputId": "7de1f5f6-6c43-44f4-9334-8bd5923c17a2"
   },
   "id": "F9XbKo9ENsGN",
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "REPORT TEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive     0.7338    0.5214    0.6097      3124\n",
      "     neutral     0.1454    0.2677    0.1885       635\n",
      "    negative     0.1667    0.2723    0.2068       584\n",
      "\n",
      "    accuracy                         0.4508      4343\n",
      "   macro avg     0.3486    0.3538    0.3350      4343\n",
      "weighted avg     0.5715    0.4508    0.4939      4343\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
